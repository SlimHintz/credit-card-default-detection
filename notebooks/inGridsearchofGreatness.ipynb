{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "# utility/data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "import pickle \n",
    "\n",
    "\n",
    "# chart creations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# pre processing\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import TomekLinks # down sampling\n",
    "from imblearn.over_sampling import SMOTE # up sampling\n",
    "\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Model Validation \n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, roc_curve\n",
    "\n",
    "# statistical testing\n",
    "from scipy.stats import f_oneway\n",
    "from scipy import stats\n",
    "\n",
    "# # py file\n",
    "# import src\n",
    "\n",
    "filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>other</th>\n",
       "      <th>post_grad</th>\n",
       "      <th>university</th>\n",
       "      <th>married</th>\n",
       "      <th>deli</th>\n",
       "      <th>credit_utility</th>\n",
       "      <th>bills</th>\n",
       "      <th>...</th>\n",
       "      <th>pay_4_-1</th>\n",
       "      <th>pay_4_0</th>\n",
       "      <th>pay_4_5</th>\n",
       "      <th>pay_5_-1</th>\n",
       "      <th>pay_5_0</th>\n",
       "      <th>pay_5_5</th>\n",
       "      <th>pay_6_-2</th>\n",
       "      <th>pay_6_-1</th>\n",
       "      <th>pay_6_2</th>\n",
       "      <th>pay_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102188</td>\n",
       "      <td>-0.809241</td>\n",
       "      <td>0.927540</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>-0.737375</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>1.09753</td>\n",
       "      <td>0.182284</td>\n",
       "      <td>1.610877</td>\n",
       "      <td>1.917156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48624</td>\n",
       "      <td>0.909141</td>\n",
       "      <td>-0.033722</td>\n",
       "      <td>-0.475185</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>-0.440771</td>\n",
       "      <td>-0.487792</td>\n",
       "      <td>-0.317849</td>\n",
       "      <td>-0.041611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.283096</td>\n",
       "      <td>-0.809241</td>\n",
       "      <td>1.360372</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>-0.737375</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>1.09753</td>\n",
       "      <td>-1.847078</td>\n",
       "      <td>-0.979926</td>\n",
       "      <td>-0.692912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48624</td>\n",
       "      <td>-1.099939</td>\n",
       "      <td>-0.033722</td>\n",
       "      <td>-0.475185</td>\n",
       "      <td>-1.137763</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>2.268752</td>\n",
       "      <td>-0.487792</td>\n",
       "      <td>-0.317849</td>\n",
       "      <td>-0.041611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.822493</td>\n",
       "      <td>-0.809241</td>\n",
       "      <td>0.819332</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>1.356162</td>\n",
       "      <td>-0.935829</td>\n",
       "      <td>1.09753</td>\n",
       "      <td>0.689625</td>\n",
       "      <td>-0.964677</td>\n",
       "      <td>-0.700861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48624</td>\n",
       "      <td>0.909141</td>\n",
       "      <td>-0.033722</td>\n",
       "      <td>-0.475185</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>-0.440771</td>\n",
       "      <td>2.050055</td>\n",
       "      <td>-0.317849</td>\n",
       "      <td>-0.041611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564529</td>\n",
       "      <td>1.235726</td>\n",
       "      <td>0.711124</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>1.356162</td>\n",
       "      <td>-0.935829</td>\n",
       "      <td>1.09753</td>\n",
       "      <td>0.182284</td>\n",
       "      <td>-0.336708</td>\n",
       "      <td>0.227059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48624</td>\n",
       "      <td>0.909141</td>\n",
       "      <td>-0.033722</td>\n",
       "      <td>-0.475185</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>-0.440771</td>\n",
       "      <td>-0.487792</td>\n",
       "      <td>-0.317849</td>\n",
       "      <td>-0.041611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.514266</td>\n",
       "      <td>-0.809241</td>\n",
       "      <td>-0.803787</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>-0.737375</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>1.09753</td>\n",
       "      <td>0.858738</td>\n",
       "      <td>0.902294</td>\n",
       "      <td>0.338219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48624</td>\n",
       "      <td>0.909141</td>\n",
       "      <td>-0.033722</td>\n",
       "      <td>-0.475185</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>-0.440771</td>\n",
       "      <td>-0.487792</td>\n",
       "      <td>3.146153</td>\n",
       "      <td>-0.041611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal      male       age     other  post_grad  university  married  \\\n",
       "0   0.102188 -0.809241  0.927540 -0.126515  -0.737375    1.068571  1.09753   \n",
       "1  -0.283096 -0.809241  1.360372 -0.126515  -0.737375    1.068571  1.09753   \n",
       "2  -0.822493 -0.809241  0.819332 -0.126515   1.356162   -0.935829  1.09753   \n",
       "3   0.564529  1.235726  0.711124 -0.126515   1.356162   -0.935829  1.09753   \n",
       "4  -0.514266 -0.809241 -0.803787 -0.126515  -0.737375    1.068571  1.09753   \n",
       "\n",
       "       deli  credit_utility     bills  ...  pay_4_-1   pay_4_0   pay_4_5  \\\n",
       "0  0.182284        1.610877  1.917156  ...  -0.48624  0.909141 -0.033722   \n",
       "1 -1.847078       -0.979926 -0.692912  ...  -0.48624 -1.099939 -0.033722   \n",
       "2  0.689625       -0.964677 -0.700861  ...  -0.48624  0.909141 -0.033722   \n",
       "3  0.182284       -0.336708  0.227059  ...  -0.48624  0.909141 -0.033722   \n",
       "4  0.858738        0.902294  0.338219  ...  -0.48624  0.909141 -0.033722   \n",
       "\n",
       "   pay_5_-1   pay_5_0   pay_5_5  pay_6_-2  pay_6_-1   pay_6_2   pay_6_7  \n",
       "0 -0.475185  0.878918 -0.027227 -0.440771 -0.487792 -0.317849 -0.041611  \n",
       "1 -0.475185 -1.137763 -0.027227  2.268752 -0.487792 -0.317849 -0.041611  \n",
       "2 -0.475185  0.878918 -0.027227 -0.440771  2.050055 -0.317849 -0.041611  \n",
       "3 -0.475185  0.878918 -0.027227 -0.440771 -0.487792 -0.317849 -0.041611  \n",
       "4 -0.475185  0.878918 -0.027227 -0.440771 -0.487792  3.146153 -0.041611  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df_train = pd.read_csv('../data/holdout_compatible_train.csv')\n",
    "df_holdout = pd.read_csv('../data/holdout_final.csv')\n",
    "df_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2 = PolynomialFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log scale continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = [\n",
    "    'limit_bal',\n",
    "    'age',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "log_scaled_train = np.log(df_train[to_scale])\n",
    "# Holdout\n",
    "log_scaled_holdout = np.log(df_holdout[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "log_scaled_train.columns = ['log_'+x for x in log_scaled_train.columns]\n",
    "\n",
    "# rename columns\n",
    "log_scaled_holdout.columns = ['log_'+x for x in log_scaled_holdout.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the log scaled features in my train data set\n",
    "df_log_train = pd.concat([df_train, log_scaled_train], axis=1)\n",
    "\n",
    "# Include the log sclaed features in my holdout data set\n",
    "df_log_holdout = pd.concat([df_holdout, log_scaled_holdout], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log_holdout.columns == df_log_train.drop(columns=['default']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdup complete up to here aka no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16874, 44), (5625, 44), (16874, 1), (5625, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "X = df_log_train.drop(columns=['default'])\n",
    "y = df_log_train[['default']]\n",
    "\n",
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# normalize the data\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X_train_scaled = scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.transform(X_test)\n",
    "\n",
    "# same scal\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the log scaled cross validation is 0.5301275820443356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=100, \n",
    "                            l1_ratio=0.5\n",
    "                            )\n",
    "\n",
    "logReg.fit(X_train_scaled, y_train)\n",
    "y_hat = logReg.predict(X_test_scaled)\n",
    "f1_score(y_test, y_hat)\n",
    "arr = cross_val_score(logReg, X_train_scaled, y_train, cv=10, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "delinquency_CV = np.mean(arr)    \n",
    "print(f\"the log scaled cross validation is {delinquency_CV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek links\n",
    "\n",
    "## preventing leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the object\n",
    "# tl = TomekLinks()\n",
    "# # resample the data\n",
    "# X_res_train, y_res_train = tl.fit_resample(X_train.as_matrix(),y_train.as_matrix())\n",
    "\n",
    "# # conform back to data frames\n",
    "# df_X_train_res = pd.DataFrame(np.matrix(X_res_train))\n",
    "# df_y_train_res = pd.DataFrame(np.matrix(y_res_train))\n",
    "\n",
    "# # rename columns\n",
    "# df_X_train_res.columns = X_train.columns\n",
    "# df_y_train_res = df_y_train_res.T\n",
    "# df_y_train_res.columns = ['default']\n",
    "\n",
    "# # Make the res X\n",
    "\n",
    "\n",
    "# # resample test data\n",
    "# X_res_test, y_res_test = tl.fit_sample(X_test.as_matrix(),y_test.as_matrix())\n",
    "\n",
    "# # conform back to data frames\n",
    "# df_X_res_test = pd.DataFrame(np.matrix(X_res_test))\n",
    "# df_y_res_test = pd.DataFrame(np.matrix(y_res_test))\n",
    "\n",
    "# # rename columns\n",
    "# df_X_res_test.columns = X_test.columns\n",
    "# df_y_res_test = df_y_res_test.T\n",
    "# df_y_res_test.columns = ['default']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logReg = LogisticRegression(class_weight = 'balanced',\n",
    "#                             C=0.01,\n",
    "#                             solver='saga', \n",
    "#                             penalty='elasticnet',\n",
    "#                             max_iter=100, \n",
    "#                             l1_ratio=0.5\n",
    "#                             )\n",
    "# logReg.fit(df_X_train_res, df_y_train_res)\n",
    "\n",
    "# y_hat = logReg.predict(df_X_res_test)\n",
    "\n",
    "# print(f1_score(df_y_res_test, y_hat))\n",
    "\n",
    "# arr = cross_val_score(logReg, df_X_train_res, df_y_train_res, cv=10, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "# delinquency_CV = np.mean(arr)    \n",
    "# print(f\"the log scaled cross validation is {delinquency_CV}\")\n",
    "# np.std(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek links standard.\n",
    "\n",
    "### do you have to upsample or downsample your test?\n",
    "\n",
    "# Remember this code block. It's important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_log_train.drop(columns=['default'])\n",
    "y = df_log_train[['default']]\n",
    "\n",
    "# test trin split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "#Instantiate the object\n",
    "tl = TomekLinks()\n",
    "# resample the data\n",
    "X_res, y_res = tl.fit_resample(X_train.as_matrix(),y_train.as_matrix())\n",
    "\n",
    "# conform back to data frames\n",
    "df_X_res = pd.DataFrame(np.matrix(X_res))\n",
    "df_y_res = pd.DataFrame(np.matrix(y_res))\n",
    "\n",
    "# rename the columns\n",
    "df_X_res.columns = X.columns\n",
    "df_y_res = df_y_res.T\n",
    "df_y_res.columns = ['default']\n",
    "\n",
    "# join them back together\n",
    "df_res=pd.concat([df_X_res, df_y_res],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X_train_scaled = scalar.fit_transform(df_X_res)\n",
    "X_test_scaled = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5570079883805374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log scaled, standard scaled cross validation with tomek links is 0.5546837465842007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5546837465842007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=1000, \n",
    "                            l1_ratio=0.3\n",
    "                            )\n",
    "\n",
    "# fit to the downsampled, scaled data\n",
    "logReg.fit(X_train_scaled, df_y_res)\n",
    "\n",
    "# predict on the none sampled, scaled test data\n",
    "y_hat = logReg.predict(X_test_scaled)\n",
    "\n",
    "# f1 score\n",
    "print(f1_score(y_test, y_hat))\n",
    "\n",
    "# cross validation\n",
    "arr = cross_val_score(logReg, X_train_scaled, df_y_res, cv=15, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "tomek_log_CV = np.mean(arr)    \n",
    "print(f\"log scaled, standard scaled cross validation with tomek links is {tomek_log_CV}\")\n",
    "np.std(arr)\n",
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The current best model is log scaled, standard scaled, with tomek links and balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search  Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest_grid_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,7),\n",
    "    'min_samples_leaf': range(2,5,1),\n",
    "    'max_features' : [5,'sqrt', 8,9,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=RandomForestClassifier(criterion='entropy', max_depth=4,\n",
       "                                              max_features='sqrt',\n",
       "                                              min_samples_leaf=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(2, 7),\n",
       "                         'max_features': [5, 'sqrt', 8, 9, 10],\n",
       "                         'min_samples_leaf': range(2, 5)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = GridSearchCV(forest, forest_grid_params, n_jobs=-1, cv=10, verbose = 1 )\n",
    "forest_clf.fit(X_train_scaled, df_y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8079501318731112"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5047193243914555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48514605414392337"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest= forest_clf.best_estimator_\n",
    "y_hat=best_forest.predict(X_test_scaled)\n",
    "\n",
    "# f1 score\n",
    "print(f1_score(y_test, y_hat))\n",
    "arr = cross_val_score(best_forest, X_train_scaled, df_y_res, cv=15, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest performs worse than just logistic regression\n",
    "\n",
    "# Let's try bagging using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5595325054784513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagger = BaggingClassifier(base_estimator=logReg,\n",
    "                           n_estimators = 30,\n",
    "                           verbose=1, \n",
    "                           max_samples=0.66,\n",
    "                           max_feature = 0.66)\n",
    "bagger.fit(X_train_scaled, df_y_res)\n",
    "y_hat = bagger.predict(X_test_scaled)\n",
    "print(f1_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 13.3min finished\n"
     ]
    }
   ],
   "source": [
    "arr = cross_val_score(bagger, X_train_scaled, df_y_res,  cv=15, scoring='f1', verbose = 1, n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553649296974794"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bagger = BaggingClassifier(base_estimator=logReg,\n",
    "                           n_estimators = 30,\n",
    "                           verbose=1, \n",
    "                           max_samples=0.9,\n",
    "                           max_features = 0.8, oob_score=True)\n",
    "bagger.fit(X_train_scaled, df_y_res)\n",
    "y_hat_1 = bagger.predict(X_test_scaled)\n",
    "print(f1_score(y_test, y_hat_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_grid = LogisticRegression(penalty='elasticnet',\n",
    "                                 solver='saga',\n",
    "                                 verbose = 1, \n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=42 )\n",
    "param_grid = {\n",
    "    'C' : np.linspace(0.01, 1, 20),\n",
    "    'l1_ratio' : np.linspace(0.01, 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 43.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_clv = GridSearchCV(estimator=logReg_grid,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='f1',\n",
    "                        n_jobs=-1, \n",
    "                        verbose=1, cv=10)\n",
    "grid_clv.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.6873684210526316, 'l1_ratio': 0.21842105263157896}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old params = {'C': 0.21842105263157896, 'l1_ratio': 0.8957894736842106}\n",
    "grid_clv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49170437405731526"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_model = grid_clv.best_estimator_\n",
    "best_log_model.fit(X_train_scaled, y_train)\n",
    "y_hat = best_log_model.predict(X_test_scaled)\n",
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5698911747001935"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=1000, \n",
    "                            l1_ratio=0.5\n",
    "                            )\n",
    "arr = cross_val_score(logReg, X_train_scaled, y_train, cv=10, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5363565285379204"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train_scaled, y_train)\n",
    "y_hat = logReg.predict(X_test_scaled)\n",
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the logistic regression model\n",
    "scalar_pickle_out = open(\"../logReg_tomek.pickle\",\"wb\")\n",
    "pickle.dump(logReg, scalar_pickle_out)\n",
    "scalar_pickle_out.close()\n",
    "\n",
    "scalar_pickle_out = open(\"../tomek_link_logReg.pickle\",\"wb\")\n",
    "pickle.dump(tl, scalar_pickle_out)\n",
    "scalar_pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46311858076563966"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=5, n_jobs=-1, p=5)\n",
    "\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "y_hat = knn_clf.predict(X_test_scaled)\n",
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf = VotingClassifier(\n",
    "    estimators= [\n",
    "        ('lr',logReg),\n",
    "        ('knn', knn_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    "    )\n",
    "vote_clf1 = vote_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = vote_clf1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5171645118145342"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-445da6deb2d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# generate cross val predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mforest_1_CV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# instantiate a forest object\n",
    "forest = RandomForestClassifier(criterion = 'entropy', max_depth = 4, max_features = 'sqrt', min_samples_leaf= 2)\n",
    "# generate cross val predictions\n",
    "arr = cross_val_score(forest, X_train_scaled, y_train, cv=10, scoring='f1', verbose = 1, n_jobs=-1)\n",
    "\n",
    "forest_1_CV = np.mean(arr)    \n",
    "\n",
    "print(f\"the random forest cross validation is {forest_1_CV}\")\n",
    "\n",
    "# creating our parameters to test\n",
    "param_dict={\n",
    "    'max_depth': range(1,10,1),\n",
    "    'min_samples_leaf': range(1,6,1),\n",
    "    'max_leaf_nodes': [None, 17,20,15],\n",
    "    'min_samples_split': range(2,10, 1)\n",
    "}\n",
    "\n",
    "\n",
    "grid_tree=GridSearchCV(decision_tree,\n",
    "                       param_grid = param_dict,\n",
    "                       cv=10, \n",
    "                       scoring='f1',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "\n",
    "# grid_tree.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-4bd084eb2982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                         cv=10)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "kNN_param_grid = {\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'n_neighbors': range(1, 10, 1),\n",
    "    'n_jobs': [-1],\n",
    "    'p' : [2,3,4]\n",
    "}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_clf,\n",
    "                        param_grid=kNN_param_grid,\n",
    "                        scoring='f1',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=1,\n",
    "                        cv=10)\n",
    "\n",
    "knn_grid.fit(X_train_scaled, y_train.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>other</th>\n",
       "      <th>post_grad</th>\n",
       "      <th>university</th>\n",
       "      <th>married</th>\n",
       "      <th>deli</th>\n",
       "      <th>credit_utility</th>\n",
       "      <th>bills</th>\n",
       "      <th>...</th>\n",
       "      <th>pay_5_-1</th>\n",
       "      <th>pay_5_0</th>\n",
       "      <th>pay_5_5</th>\n",
       "      <th>pay_6_-2</th>\n",
       "      <th>pay_6_-1</th>\n",
       "      <th>pay_6_2</th>\n",
       "      <th>pay_6_7</th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.824600</td>\n",
       "      <td>1250323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.301383</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.206073</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.100712</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.373638</td>\n",
       "      <td>279502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.289782</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.661000</td>\n",
       "      <td>31910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20404</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.599450</td>\n",
       "      <td>234247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.596635</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20405</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-0.019574</td>\n",
       "      <td>24410.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.765688</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20406</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.058820</td>\n",
       "      <td>24806.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.512925</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20407</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>15502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20408</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.318050</td>\n",
       "      <td>96561.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20409 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       limit_bal  male   age  other  post_grad  university  married  deli  \\\n",
       "0       220000.0   0.0  36.0    0.0        1.0         0.0      0.0   0.0   \n",
       "1       200000.0   0.0  29.0    0.0        0.0         0.0      0.0  -6.0   \n",
       "2       180000.0   0.0  27.0    0.0        1.0         0.0      0.0 -12.0   \n",
       "3        80000.0   1.0  32.0    0.0        0.0         1.0      0.0   0.0   \n",
       "4        10000.0   1.0  27.0    0.0        0.0         1.0      0.0   0.0   \n",
       "...          ...   ...   ...    ...        ...         ...      ...   ...   \n",
       "20404    40000.0   0.0  38.0    0.0        0.0         1.0      1.0   9.0   \n",
       "20405   350000.0   1.0  42.0    0.0        1.0         0.0      1.0  -6.0   \n",
       "20406   100000.0   0.0  46.0    0.0        0.0         0.0      0.0   3.0   \n",
       "20407    20000.0   0.0  50.0    0.0        0.0         0.0      1.0  -8.0   \n",
       "20408    20000.0   0.0  25.0    0.0        1.0         0.0      0.0  11.0   \n",
       "\n",
       "       credit_utility      bills  ...  pay_5_-1  pay_5_0  pay_5_5  pay_6_-2  \\\n",
       "0            4.824600  1250323.0  ...       0.0      1.0      0.0       0.0   \n",
       "1            0.000000     1956.0  ...       1.0      0.0      0.0       0.0   \n",
       "2            0.000000        0.0  ...       0.0      0.0      0.0       1.0   \n",
       "3            3.373638   279502.0  ...       0.0      1.0      0.0       0.0   \n",
       "4            2.661000    31910.0  ...       0.0      1.0      0.0       0.0   \n",
       "...               ...        ...  ...       ...      ...      ...       ...   \n",
       "20404        5.599450   234247.0  ...       0.0      0.0      0.0       0.0   \n",
       "20405       -0.019574    24410.0  ...       1.0      0.0      0.0       0.0   \n",
       "20406        0.058820    24806.0  ...       1.0      0.0      0.0       0.0   \n",
       "20407        0.227600    15502.0  ...       0.0      0.0      0.0       1.0   \n",
       "20408        4.318050    96561.0  ...       0.0      0.0      0.0       0.0   \n",
       "\n",
       "       pay_6_-1  pay_6_2  pay_6_7  limit_bal       age  default  \n",
       "0           0.0      0.0      0.0  12.301383  3.583519        1  \n",
       "1           1.0      0.0      0.0  12.206073  3.367296        0  \n",
       "2           0.0      0.0      0.0  12.100712  3.295837        0  \n",
       "3           0.0      0.0      0.0  11.289782  3.465736        0  \n",
       "4           0.0      0.0      0.0   9.210340  3.295837        1  \n",
       "...         ...      ...      ...        ...       ...      ...  \n",
       "20404       0.0      1.0      0.0  10.596635  3.637586        1  \n",
       "20405       1.0      0.0      0.0  12.765688  3.737670        0  \n",
       "20406       0.0      0.0      0.0  11.512925  3.828641        0  \n",
       "20407       0.0      0.0      0.0   9.903488  3.912023        1  \n",
       "20408       0.0      1.0      0.0   9.903488  3.218876        0  \n",
       "\n",
       "[20409 rows x 45 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
